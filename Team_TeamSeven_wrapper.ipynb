{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Team_TeamSeven_wrapper.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sprerak48/MIT-Fintech-Challenge/blob/master/Team_TeamSeven_wrapper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EmjWp2fbXHA2",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JhaygZTjXHA7"
      },
      "source": [
        "**read_data_small** is the function to read in the small dataset about 30 MB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "su0ar7BzXHA8",
        "colab": {}
      },
      "source": [
        "def read_data_small():\n",
        "    X_train = pd.read_csv(\"X_train_small.csv\")\n",
        "    X_test = pd.read_csv(\"X_test_small.csv\")\n",
        "    y_train = np.asarray(pd.read_csv(\"y_train_small.csv\", header=None)[0])\n",
        "    return X_train, X_test, y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dKXdlcu-XHBJ"
      },
      "source": [
        "**detect_spoofying** is the function for training the classifier and classify the results. \n",
        "\n",
        "Here we provide an simple example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JNRG8uWgXHBK",
        "colab": {}
      },
      "source": [
        "### import libraries here ###\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "### code classifier here ###\n",
        "def format_data(df):\n",
        "\n",
        "    # append numberical columns\n",
        "    rst = df.loc[:,[\"price\",\"volume\",\"bestBid\",\"bestAsk\",'bestBidVolume',\n",
        "                    'bestAskVolume','lv2Bid', 'lv2BidVolume','lv2Ask', \n",
        "                    'lv2AskVolume', 'lv3Bid', 'lv3BidVolume', 'lv3Ask',\n",
        "                    'lv3AskVolume']]\n",
        "    \n",
        "    # encode the binaries\n",
        "    rst[\"isBid\"] = df.isBid*1\n",
        "    rst[\"isBuyer\"] = df.isBuyer*1\n",
        "    rst[\"isAggressor\"] = df.isAggressor*1\n",
        "    rst[\"type\"] = (df.type == \"ORDER\")*1\n",
        "    rst[\"source\"] = (df.source==\"USER\")*1\n",
        "    \n",
        "    # parse the order id data\n",
        "    rst[\"orderId\"] = df.orderId.str.split('-').str[-1]\n",
        "    rst[\"tradeId\"] = df.tradeId.str.split('-').str[-1]\n",
        "    rst[\"bidOrderId\"] = df.bidOrderId.str.split('-').str[-1]\n",
        "    rst[\"askOrderId\"] = df.askOrderId.str.split('-').str[-1]\n",
        "    \n",
        "    # encode the multiple lable data\n",
        "    tmp_operation = pd.DataFrame(pd.get_dummies(df.operation), columns=df.operation.unique()[:-1])\n",
        "    rst = pd.concat([rst, tmp_operation], axis=1)\n",
        "    tmp_endUserRef = pd.DataFrame(pd.get_dummies(df.endUserRef), columns=df.endUserRef.unique()[:-1])\n",
        "    rst = pd.concat([rst, tmp_endUserRef], axis=1)\n",
        "    \n",
        "    return rst\n",
        "\n",
        "def detect_spoofying(X_train, X_test, y_train):\n",
        "    \n",
        "    # clean up the data\n",
        "    X_concat = pd.concat([X_train, X_test])\n",
        "    X_clean = format_data(X_concat)\n",
        "    \n",
        "    # feel free to add more columns inferred from data\n",
        "    # smartly engineered features can be very useful to improve the classification resutls\n",
        "    X_clean[\"timeSinceLastTrade\"] = pd.concat([X_train.loc[:,[\"timestamp\",\"endUserRef\"]].groupby(\"endUserRef\").diff(),\n",
        "                                              X_test.loc[:,[\"timestamp\",\"endUserRef\"]].groupby(\"endUserRef\").diff()])\n",
        "    \n",
        "    X_clean = X_clean.fillna(-1)\n",
        "    X_train_clean = X_clean.iloc[:X_train.shape[0],:]\n",
        "    X_test_clean = X_clean.iloc[X_train.shape[0]:,:]\n",
        "    X_train_clean_scaled = scale(X_train_clean)\n",
        "    X_test_clean_scaled = scale(X_test_clean)\n",
        "\n",
        "    #xgboost\n",
        "    model = XGBClassifier().fit(X_train_clean_scaled, y_train,eval_metric=\"logloss\")\n",
        "    y_train_pred_x = model.predict_proba(X_train_clean_scaled)\n",
        "    y_test_pred_x = model.predict_proba(X_test_clean_scaled)\n",
        "\n",
        "    #naive bayes\n",
        "    classifier = GaussianNB().fit(X_train_clean_scaled, y_train)\n",
        "    y_train_pred_n = model.predict_proba(X_train_clean_scaled)\n",
        "    y_test_pred_n = classifier.predict_proba(X_test_clean_scaled)\n",
        "\n",
        "    #knn\n",
        "    cl = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2).fit(X_train_clean_scaled, y_train)\n",
        "    y_train_pred_k = model.predict_proba(X_train_clean_scaled)\n",
        "    y_test_pred_k = cl.predict_proba(X_test_clean_scaled)\n",
        "\n",
        "    #MLP\n",
        "    clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1).fit(X_train_clean_scaled, y_train)\n",
        "    y_train_mlp = clf.predict_proba(X_train_clean_scaled)\n",
        "    y_test_mlp = clf.predict_proba(X_test_clean_scaled)\n",
        "\n",
        "    return  y_train_pred_x, y_test_pred_x,  y_train_mlp, y_test_mlp \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJsBEygJ-ieC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### import libraries here ###\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "### code classifier here ###\n",
        "def format_data(df):\n",
        "\n",
        "    # append numberical columns\n",
        "    rst = df.loc[:,[\"price\",\"volume\",\"bestBid\",\"bestAsk\",'bestBidVolume',\n",
        "                    'bestAskVolume','lv2Bid', 'lv2BidVolume','lv2Ask', \n",
        "                    'lv2AskVolume', 'lv3Bid', 'lv3BidVolume', 'lv3Ask',\n",
        "                    'lv3AskVolume']]\n",
        "    \n",
        "    # encode the binaries\n",
        "    rst[\"isBid\"] = df.isBid*1\n",
        "    rst[\"isBuyer\"] = df.isBuyer*1\n",
        "    rst[\"isAggressor\"] = df.isAggressor*1\n",
        "    rst[\"type\"] = (df.type == \"ORDER\")*1\n",
        "    rst[\"source\"] = (df.source==\"USER\")*1\n",
        "    \n",
        "    # parse the order id data\n",
        "    rst[\"orderId\"] = df.orderId.str.split('-').str[-1]\n",
        "    rst[\"tradeId\"] = df.tradeId.str.split('-').str[-1]\n",
        "    rst[\"bidOrderId\"] = df.bidOrderId.str.split('-').str[-1]\n",
        "    rst[\"askOrderId\"] = df.askOrderId.str.split('-').str[-1]\n",
        "    \n",
        "    # encode the multiple lable data\n",
        "    tmp_operation = pd.DataFrame(pd.get_dummies(df.operation), columns=df.operation.unique()[:-1])\n",
        "    rst = pd.concat([rst, tmp_operation], axis=1)\n",
        "    tmp_endUserRef = pd.DataFrame(pd.get_dummies(df.endUserRef), columns=df.endUserRef.unique()[:-1])\n",
        "    rst = pd.concat([rst, tmp_endUserRef], axis=1)\n",
        "    \n",
        "    return rst\n",
        "\n",
        "def detect_spoofying_2(X_train, X_test, y_train):\n",
        "    \n",
        "    # clean up the data\n",
        "    X_concat = pd.concat([X_train, X_test])\n",
        "    X_clean = format_data(X_concat)\n",
        "    \n",
        "    # feel free to add more columns inferred from data\n",
        "    # smartly engineered features can be very useful to improve the classification resutls\n",
        "    X_clean[\"timeSinceLastTrade\"] = pd.concat([X_train.loc[:,[\"timestamp\",\"endUserRef\"]].groupby(\"endUserRef\").diff(),\n",
        "                                              X_test.loc[:,[\"timestamp\",\"endUserRef\"]].groupby(\"endUserRef\").diff()])\n",
        "    \n",
        "    X_clean = X_clean.fillna(-1)\n",
        "    X_train_clean = X_clean.iloc[:X_train.shape[0],:]\n",
        "    X_test_clean = X_clean.iloc[X_train.shape[0]:,:]\n",
        "    X_train_clean_scaled = scale(X_train_clean)\n",
        "    X_test_clean_scaled = scale(X_test_clean)\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xzMuIqzgXHBY",
        "colab": {}
      },
      "source": [
        "def wrapper():\n",
        "    # read in data\n",
        "    X_train, X_test, y_train = read_data_small()\n",
        "    # or if you have the computational power to work with the big data set, \n",
        "    # you can comment out the read_data_samll line and uncomment the following read_data_big\n",
        "    # X_train, X_test, y_train = read_data_big()\n",
        "    \n",
        "    # process the data, train classifier and output probability matrix\n",
        "    y_train_pred_x, y_test_pred_x,  y_train_mlp, y_test_mlp  = detect_spoofying(X_train, X_test, y_train)\n",
        "    \n",
        "    # return the prediciton values\n",
        "    return y_train_pred_x, y_test_pred_x,  y_train_mlp, y_test_mlp "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OepXvwqtXHBb"
      },
      "source": [
        "Call function wrapper:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Kd1gAIuHXHBb",
        "colab": {}
      },
      "source": [
        "y_train_pred_x, y_test_pred_x,  y_train_mlp, y_test_mlp  = wrapper()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBRJylsfm2N4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(y_test_mlp).to_csv('MLP prediction probabilities.csv')\n",
        "pd.DataFrame(y_test_mlp).to_csv('XGBoost prediction probabilities.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}